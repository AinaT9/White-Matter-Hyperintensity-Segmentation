{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import  DataLoader, ConcatDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import nibabel\n",
    "from preprocessing import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd() + \"\\\\data\"\n",
    "TRAINING_PATH_AMSTERDAM= BASE_PATH + \"\\\\training\\\\Amsterdam\\\\GE3T\\\\\"\n",
    "TRAINING_PATH_SINGAPORE= BASE_PATH + \"\\\\training\\\\Singapore\\\\\"\n",
    "TRAINING_PATH_UTRECHT= BASE_PATH + \"\\\\training\\\\Utrecht\\\\\"\n",
    "\n",
    "TEST_PATH_AMSTERDAM= BASE_PATH + \"\\\\test\\\\Amsterdam\\\\\"\n",
    "TEST_PATH_SINGAPORE= BASE_PATH + \"\\\\test\\\\Singapore\\\\\"\n",
    "TEST_PATH_UTRECHT= BASE_PATH + \"\\\\test\\\\Utrecht\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICCIONARIO TRAINING Y TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DICT={\n",
    "    \"pathsFLAIR\":[],\n",
    "    \"pathsT1\":[],\n",
    "    \"mask\" :[],\n",
    "    \"location\":[]\n",
    "}\n",
    "createDictionary(TRAINING_PATH_UTRECHT, TRAINING_DICT,\"Utrecht\")\n",
    "createDictionary(TRAINING_PATH_SINGAPORE, TRAINING_DICT, \"Singapore\")\n",
    "createDictionary(TRAINING_PATH_AMSTERDAM, TRAINING_DICT,\"Amsterdam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DICT={\n",
    "    \"pathsFLAIR\":[],\n",
    "    \"pathsT1\":[],\n",
    "    \"mask\" :[],\n",
    "    \"location\":[]\n",
    "}\n",
    "createDictionary(TEST_PATH_UTRECHT, TEST_DICT,\"Utrecht\")\n",
    "createDictionary(TEST_PATH_SINGAPORE, TEST_DICT,\"Singapore\")\n",
    "createDictionary(os.path.join(TEST_PATH_AMSTERDAM, \"GE1T5\"), TEST_DICT,\"Amsterdam\")\n",
    "createDictionary(os.path.join(TEST_PATH_AMSTERDAM, \"GE3T\"), TEST_DICT,\"Amsterdam\")\n",
    "createDictionary(os.path.join(TEST_PATH_AMSTERDAM, \"Philips_VU .PETMR_01\"), TEST_DICT,\"Amsterdam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear dataset entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training FLAIR images 48\n",
      "total test FLAIR images 12\n"
     ]
    }
   ],
   "source": [
    "train,val=divideDataset(TRAINING_DICT,0.8)\n",
    "print(\"total training FLAIR images\", len(train.__getitem__(\"pathsFLAIR\")))\n",
    "print(\"total test FLAIR images\", len(val.__getitem__(\"pathsFLAIR\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128), antialias=True),\n",
    "])\n",
    "\n",
    "transform_label=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128,128), antialias=True, interpolation= transforms.InterpolationMode.NEAREST),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,False)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,False)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=True)\n",
    "print(train_dl.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Cropping and padding\n",
    "- obtiene region cerebral, se rellenan los huecos que pueda haber, se normaliza con gaussian normalization\n",
    "- las imágenes finales tienen 2 canales ya que ponen una encima de la otra T1 Y FLAIR\n",
    "- removing skull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "flair= os.path.join(TRAINING_PATH_AMSTERDAM, \"100\",\"pre\",\"T1.nii.gz\")\n",
    "img = nibabel.load(flair)\n",
    "image_data = img.get_fdata() \n",
    "image_orig=image_data[:, :,53]\n",
    "axs[0].imshow(image_orig, cmap='gray')\n",
    "axs[0].set_title(\"Original %s\" %(image_orig.shape,))\n",
    "axs[0].axis('off')\n",
    "\n",
    "image_res=add_transformation(image_data[:, :, 53],128, True, False)\n",
    "axs[1].imshow(image_res.squeeze(0), cmap='gray')\n",
    "axs[1].set_title(\"Resized %s\" %(image_res.shape,))\n",
    "axs[1].axis('off')\n",
    "\n",
    "image_crop=add_transformation(image_data[:, :, 53],128, False,False)\n",
    "axs[2].imshow(image_crop.squeeze(0), cmap='gray')\n",
    "axs[2].set_title(\"Cropped %s\" %(image_crop.shape,))\n",
    "axs[2].axis('off')\n",
    "\n",
    "image_pad=add_transformation(image_data[:, :, 53],256, False,False)\n",
    "axs[3].imshow(image_pad.squeeze(0), cmap='gray')\n",
    "axs[3].set_title(\"Padding %s\" %(image_pad.shape,))\n",
    "axs[3].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "flair= os.path.join(TRAINING_PATH_UTRECHT, \"19\",\"pre\",\"FLAIR.nii.gz\")\n",
    "img = nibabel.load(flair)\n",
    "image_data = img.get_fdata() \n",
    "image_crop=add_transformation(image_data[:, :, 31],200, False,False)\n",
    "axs[0].imshow(image_crop.squeeze(0), cmap='gray')\n",
    "axs[0].set_title(\"Cropped %s\" %(image_crop.shape,))\n",
    "axs[0].axis('off')\n",
    "\n",
    "flair= os.path.join(TRAINING_PATH_UTRECHT, \"19\",\"pre\",\"T1.nii.gz\")\n",
    "img = nibabel.load(flair)\n",
    "image_data = img.get_fdata() \n",
    "image_crop=add_transformation(image_data[:, :, 31],200, False,False)\n",
    "axs[1].imshow(image_crop.squeeze(0), cmap='gray')\n",
    "axs[1].set_title(\"Cropped %s\" %(image_crop.shape,))\n",
    "axs[1].axis('off')\n",
    "\n",
    "mask= os.path.join(TRAINING_PATH_UTRECHT, \"19\", \"wmh.nii.gz\")\n",
    "img = nib.load(mask)\n",
    "image_data = img.get_fdata() \n",
    "merged_image= np.array(image_data)\n",
    "merged_image[merged_image==1]=255\n",
    "merged_image[merged_image==2]=0\n",
    "merged_image[merged_image==3]=255\n",
    "image_data= merged_image\n",
    "\n",
    "\n",
    "axs[2].imshow(image_data[:, :,31], cmap='gray')\n",
    "axs[2].set_title(\"MASK\")\n",
    "axs[2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skull stripping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "flair= os.path.join(TRAINING_PATH_AMSTERDAM, \"100\",\"pre\",\"FLAIR.nii.gz\")\n",
    "t1=os.path.join(TRAINING_PATH_AMSTERDAM, \"100\",\"pre\",\"T1.nii.gz\")\n",
    "\n",
    "fl = nibabel.load(flair)\n",
    "fl_data = fl.get_fdata()[:,:,53] \n",
    "t=nibabel.load(t1)\n",
    "t_data=t.get_fdata()[:,:,53] \n",
    "image_orig=numpy.concatenate((t_data[...,np.newaxis],fl_data[...,np.newaxis]), axis=2)\n",
    "axs[0].imshow(image_orig[...,0], cmap='gray')\n",
    "axs[0].set_title(\"T1 %s\" %(image_orig.shape,))\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(image_orig[...,1], cmap='gray')\n",
    "axs[1].set_title(\"FLAIR %s\" %(image_orig.shape,))\n",
    "axs[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Filling &  Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "flair= os.path.join(TRAINING_PATH_AMSTERDAM, \"100\",\"pre\",\"T1.nii.gz\")\n",
    "img = nibabel.load(flair)\n",
    "image_data = img.get_fdata() \n",
    "image_orig=image_data[:, :,53]\n",
    "axs[0].imshow(image_orig, cmap='gray')\n",
    "axs[0].set_title(\"Original %s\" %(image_orig.shape,))\n",
    "axs[0].axis('off')\n",
    "\n",
    "\n",
    "mask= brainMask(image_orig)\n",
    "axs[1].imshow(mask, cmap='gray')\n",
    "axs[1].set_title(\"Sin rellenar\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "\n",
    "mask= brainfilling(mask)\n",
    "axs[2].imshow(mask, cmap='gray')\n",
    "axs[2].set_title(\"Rellenar\")\n",
    "axs[2].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "flair= os.path.join(TRAINING_PATH_AMSTERDAM, \"100\",\"pre\",\"T1.nii.gz\")\n",
    "img = nibabel.load(flair)\n",
    "image_data = img.get_fdata() \n",
    "image_orig=image_data[:, :,53]\n",
    "axs[0].imshow(image_orig, cmap='gray')\n",
    "axs[0].set_title(\"Original %s\" %(image_orig.shape,))\n",
    "axs[0].axis('off')\n",
    "mask_tensor= transforms.ToTensor()(mask)\n",
    "image_res=gaussian_normalizationFILL(transforms.ToTensor()(image_data[:, :, 53]), mask_tensor)\n",
    "axs[1].imshow(image_res.squeeze(0), cmap='gray')\n",
    "axs[1].set_title(\"Gaussian Normalization %s\" %(image_res.shape,))\n",
    "axs[1].axis('off')\n",
    "\n",
    "image_crop=minmax_normalizationFILL(transforms.ToTensor()(image_data[:, :, 53]), mask_tensor)\n",
    "axs[2].imshow(image_crop.squeeze(0), cmap='gray')\n",
    "axs[2].set_title(\"MinMax %s\" %(image_crop.shape,))\n",
    "axs[2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MÉTODOS ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet \n",
    "use_cuda = False\n",
    "torch.manual_seed(33)\n",
    "\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model = UNet(in_channels=1,out_channels=1, init_features=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintestpipeline(epochs: int, optim: Adam, criterion: DiceLoss, min_loss: int, name: str):\n",
    "    t_loss = np.zeros((epochs))\n",
    "    v_loss = np.zeros((epochs))\n",
    "    pbar = tqdm(range(1, epochs+1)) # tdqm permet tenir text dinàmic\n",
    "    for epoch in pbar:\n",
    "        \n",
    "        train_loss = 0 \n",
    "        val_loss = 0  \n",
    "        \n",
    "        model.train()                                                  \n",
    "        for batch_num, (input_img, target) in enumerate(train_dl, 1):   \n",
    "        \n",
    "\n",
    "            input_img= input_img.to(device).float()\n",
    "            target = target.to(device)\n",
    "            \n",
    "            \n",
    "            output = model(input_img)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()                                            \n",
    "            optim.step()                                               \n",
    "            optim.zero_grad()     \n",
    "            \n",
    "            train_loss += loss.item()    \n",
    "                                                        \n",
    "        model.eval()   \n",
    "        with torch.no_grad():                                          \n",
    "            for input_img, target in val_dl: \n",
    "                input_img = input_img.to(device).float()\n",
    "                target = target.to(device)\n",
    "                \n",
    "                output = model(input_img)                                   \n",
    "                loss = criterion(output, target)   \n",
    "                val_loss += loss.item()  \n",
    "        \n",
    "        # RESULTATS\n",
    "        train_loss /= len(train_dl)\n",
    "        t_loss[epoch-1] = train_loss\n",
    "        \n",
    "        val_loss /= len(val_dl)   \n",
    "        v_loss[epoch-1] = val_loss\n",
    "        if(v_loss[epoch-1]<min_loss):\n",
    "            min_loss=v_loss[epoch-1]\n",
    "            torch.save(model.state_dict(), name)  \n",
    "        # VISUALITZACIO DINAMICA\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        pl.plot(t_loss[:epoch], label=\"train\")\n",
    "        pl.plot(v_loss[:epoch], label=\"validation\")\n",
    "        pl.legend()\n",
    "        pl.xlim(0, epochs)\n",
    "        pl.xticks(range(0,epochs,1),range(1,epochs+1,1))\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        plt.close()\n",
    "\n",
    "        pbar.set_description(f\"Epoch:{epoch} Training Loss:{train_loss} Validation Loss:{val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "\n",
    "def calculate_metrics(model, test_dl, device):\n",
    "    model.eval()\n",
    "    total_dice = 0\n",
    "    total_hd = 0\n",
    "    total = len(test_dl)\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "    hd_metric = HausdorffDistanceMetric(include_background=True, reduction=\"mean\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_img, target in test_dl:\n",
    "            input_img = input_img.to(device).float()\n",
    "            target = target.to(device).float()\n",
    "\n",
    "            output = model(input_img)\n",
    "\n",
    "            dice = dice_metric(output, target)\n",
    "            dice = np.nan_to_num(dice.cpu().numpy())\n",
    "            total_dice += dice.mean()\n",
    "\n",
    "        \n",
    "            hd = hd_metric(output, target)\n",
    "            hd = np.nan_to_num(hd.cpu().numpy())\n",
    "            total_hd += hd.mean()\n",
    "        \n",
    "            # Compute confusion matrix\n",
    "            #confusion_matrix = get_confusion_matrix(pred_binary, target)\n",
    "            \n",
    "\n",
    "    total_dice /= total\n",
    "    total_hd /= total\n",
    "\n",
    "    print(\"Dice coefficient:\", total_dice)\n",
    "    print(\"Hausdorff Distance:\", total_hd)\n",
    "    # print(\"Sensitivity:\", total_sensitivity)\n",
    "    # print(\"Specificity:\", total_specificity)\n",
    "    # print(\"Precision:\", total_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignPretrainedModel(device,name:str):\n",
    "    mmodel =  model.to(device)\n",
    "    mmodel.load_state_dict(torch.load(name))\n",
    "    mmodel.eval();\n",
    "    return mmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con todo el conjunto de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(128,True)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,False)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,False)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/NODeletion128FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/NODeletion128FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,False)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,False)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/NODeletion128T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/NODeletion128T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo sin el 20% de los slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(128,True)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/Deletion128FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/Deletion128FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/Deletion128T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/Deletion128T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos con Resize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se asume que sin los slices el modelo es mejor(Pendiente de los resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 128x128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(128,True)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize128FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize128FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize128T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize128T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256 x 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(256,True)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 384 x 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(384,True)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize384FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize384FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize384T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize384T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 x 200 (modificación unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(200,True)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize200FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize200FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/RESIZE/Resize200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/RESIZE/Resize200T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos con Crop/Pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 x 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(200,False)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop200FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop200FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop200T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 240 x240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=1,out_channels=1, init_features=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(240,False)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop240FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop240FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop240T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop240T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256 x 256 (solving padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(256,False)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 384 x 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_setter(384,False)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label, False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop384FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop384FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/CROP/Crop384T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/CROP/Crop384T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos con Normalizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se asume un tamaño con Reize de 256x256(pendiente resultados)\n",
    "Se asume un tamaño con Crop and Pad de 200x200(pendiente resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Normalization Resize 256x256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1: Gaussian normalization\n",
    "- 3: Gaussian Normalization cerebro\n",
    "- 5: gaussian normalization del cerebro completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,1)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_RESIZE/GN256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/GN_RESIZE/GN256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,1)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_RESIZE/GN256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/GN_RESIZE/GN256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,3)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_RESIZE/GNMask256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/GN_RESIZE/GNMask256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,3)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_RESIZE/GNMask256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/GN_RESIZE/GNMask256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,5)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_RESIZE/GNFill256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/GN_RESIZE/GNFill256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,5)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_RESIZE/GNFill256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/GN_RESIZE/GNFill256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINMAX NORMALIZATION RESIZE 256X256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2: min max normalization\n",
    "- 4: min max del cerebro\n",
    "- 6: minmax del cerebro entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,2)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_RESIZE/MM256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/MM_RESIZE/MM256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(256,True,2)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_RESIZE/MM256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/MM_RESIZE/MM256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "transform, transform_label=transform_normalization(256,True,4)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss() \n\u001b[0;32m      4\u001b[0m min_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtraintestpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Modelos3DUNET/MM_RESIZE/MMmask256FLAIR.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m, in \u001b[0;36mtraintestpipeline\u001b[1;34m(epochs, optim, criterion, min_loss, name)\u001b[0m\n\u001b[0;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_img)\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                                            \n\u001b[0;32m     21\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()                                               \n\u001b[0;32m     22\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()     \n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_RESIZE/MMmask256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/MM_RESIZE/MMmask256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "transform, transform_label=transform_normalization(256,True,4)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:40<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss() \n\u001b[0;32m      4\u001b[0m min_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtraintestpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Modelos3DUNET/MM_RESIZE/MMmask256T1.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mtraintestpipeline\u001b[1;34m(epochs, optim, criterion, min_loss, name)\u001b[0m\n\u001b[0;32m     14\u001b[0m input_img\u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()                                            \n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\OneDrive\\Escritorio\\White-Matter-Hyperintensity-Segmentation\\unet.py:60\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder3(dec3)\n\u001b[0;32m     59\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv2(dec3)\n\u001b[1;32m---> 60\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder2(dec2)\n\u001b[0;32m     62\u001b[0m dec1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv1(dec2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_RESIZE/MMmask256T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/MM_RESIZE/MMmask256T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "transform, transform_label=transform_normalization(256,True,6)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss() \n\u001b[0;32m      4\u001b[0m min_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtraintestpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Modelos3DUNET/MM_RESIZE/MMFill256FLAIR.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mtraintestpipeline\u001b[1;34m(epochs, optim, criterion, min_loss, name)\u001b[0m\n\u001b[0;32m     14\u001b[0m input_img\u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()                                            \n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\OneDrive\\Escritorio\\White-Matter-Hyperintensity-Segmentation\\unet.py:58\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv3(dec4)\n\u001b[0;32m     57\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dec3, enc3), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv2(dec3)\n\u001b[0;32m     60\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dec2, enc2), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_RESIZE/MMFill256FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/MM_RESIZE//MMFill256FLAIR.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "transform, transform_label=transform_normalization(256,True,6)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [01:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss() \n\u001b[0;32m      4\u001b[0m min_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtraintestpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Modelos3DUNET/MM_RESIZE/MMFill200T1.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mtraintestpipeline\u001b[1;34m(epochs, optim, criterion, min_loss, name)\u001b[0m\n\u001b[0;32m     14\u001b[0m input_img\u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()                                            \n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\OneDrive\\Escritorio\\White-Matter-Hyperintensity-Segmentation\\unet.py:62\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dec2, enc2), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     61\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder2(dec2)\n\u001b[1;32m---> 62\u001b[0m dec1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m dec1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dec1, enc1), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     64\u001b[0m dec1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder1(dec1)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\conv.py:952\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    947\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    948\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    950\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_RESIZE/MMFill200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/MM_RESIZE/MMFill200T1.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Normalization CropandPad 200x200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,1)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_CROP/GN200FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,1)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_CROP/GN200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,3)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_CROP/GNMask200FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,3)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_CROP/GNMask200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,5)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_CROP/GNFill200FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,5)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/GN_CROP/GNFill200T1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min max Normalization 200x200 crop and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,2)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_CROP/MM200Flair.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,2)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_CROP/MM200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,4)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_CROP/MMmask200Flair.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,4)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_CROP/MMmask200T1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,6)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsFLAIR\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsFLAIR\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_CROP/MMFill200FLAIR.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform, transform_label=transform_normalization(200,False,6)\n",
    "train_data,val_data,train_dl,val_dl = dataLoaders(\"pathsT1\",train,val,transform, transform_label,False,30,True)\n",
    "test_data=Slices(TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label,True)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 65\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/MM_CROP/MMFill200T1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos con skull striping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Con Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha seleccionado inicialmente crop de 240 y normalizacion fill brain gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2206\n",
      "742\n"
     ]
    }
   ],
   "source": [
    "transform, transform_label=transform_normalization(240,False,5)\n",
    "train_data,val_data,train_dl,val_dl = dataLoadersConcatenate(\"pathsFLAIR\",\"pathsT1\",train,val,transform, transform_label,False,30)\n",
    "test_data=Concatenate(TEST_DICT.get(\"pathsFLAIR\"),TEST_DICT.get(\"pathsT1\"), TEST_DICT.get(\"mask\"), transform, transform_label)\n",
    "test_dl = DataLoader(test_data, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=2, out_channels=1, init_features=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [10:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m DiceLoss() \n\u001b[0;32m      4\u001b[0m min_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtraintestpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Modelos3DUNET/pruebaConcatenate.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mtraintestpipeline\u001b[1;34m(epochs, optim, criterion, min_loss, name)\u001b[0m\n\u001b[0;32m     14\u001b[0m input_img\u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()                                            \n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\OneDrive\\Escritorio\\White-Matter-Hyperintensity-Segmentation\\unet.py:55\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m dec4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv4(bottleneck)\n\u001b[0;32m     54\u001b[0m dec4 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dec4, enc4), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m dec4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv3(dec4)\n\u001b[0;32m     57\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((dec3, enc3), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aina\\miniconda3\\envs\\tfg_aina\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = DiceLoss() \n",
    "min_loss=1000\n",
    "traintestpipeline(epochs, optim, criterion, min_loss,\"./Modelos3DUNET/pruebaConcatenate.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=assignPretrainedModel(device,\"./Modelos3DUNET/pruebaConcatenate.pt\")\n",
    "calculate_metrics(model,test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rotation (-15,15)\n",
    "- Scale (0.9,1.1)\n",
    "- Shearing(-18,18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1, 4, figsize=(15,5))\n",
    "flair= os.path.join(TRAINING_PATH_AMSTERDAM, \"100\",\"pre\",\"T1.nii.gz\")\n",
    "img = nibabel.load(flair)\n",
    "image_data = img.get_fdata() \n",
    "image_orig=image_data[:, :,53]\n",
    "axs[0].imshow(image_orig, cmap='gray')\n",
    "axs[0].set_title(\"Original %s\" %(image_orig.shape,))\n",
    "axs[0].axis('off')\n",
    "\n",
    "image_rot=dataAugmentation(image_data[:, :, 53],(-15,15),None,None)\n",
    "axs[1].imshow(image_rot.squeeze(0), cmap='gray')\n",
    "axs[1].set_title(\"Rotation %s\" %(image_rot.shape,))\n",
    "axs[1].axis('off')\n",
    "\n",
    "image_scale=dataAugmentation(image_data[:, :, 53],(0,0),(0.9,1.1),None)\n",
    "axs[2].imshow(image_scale.squeeze(0), cmap='gray')\n",
    "axs[2].set_title(\"scale %s\" %(image_scale.shape,))\n",
    "axs[2].axis('off')\n",
    "\n",
    "image_she=dataAugmentation(image_data[:, :, 53],(0,0),None,(-18,18))\n",
    "axs[3].imshow(image_she.squeeze(0), cmap='gray')\n",
    "axs[3].set_title(\"shear %s\" %(image_she.shape,))\n",
    "axs[3].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
